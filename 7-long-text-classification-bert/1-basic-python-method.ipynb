{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('ProsusAI/finbert')\n",
    "model = BertForSequenceClassification.from_pretrained('ProsusAI/finbert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(tokens):\n",
    "    #get output logits from the model\n",
    "    ouput = model(**tokens)\n",
    "    #get probabilities from softmax\n",
    "    probs = torch.nn.functional.softmax(ouput[0], dim=-1)\n",
    "    # return the probability tensor (argmax will come later)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\"\n",
    "Covered health care providers and health plans (covered entities)1 can use remote communication technologies2 to provide audio-only telehealth3 services when such communications are conducted in a manner that is consistent with the applicable requirements of the Health Insurance Portability and Accountability Act of 1996 (HIPAA) Privacy, Security, and Breach Notification Rules (HIPAA Rules).4 The U.S. Department of Health and Human Services (HHS) Office for Civil Rights (OCR) developed this guidance to help covered entities understand how they can use remote communication technologies for audio-only telehealth5 in compliance with the HIPAA Rules, including when OCR’s Notification of Enforcement Discretion for Telehealth Remote Communications (Telehealth Notification)6 is no longer in effect.7\n",
    "\n",
    "HHS is issuing this guidance on audio-only telehealth in direct response to the Executive Order on Transforming Federal Customer Experience and Service Delivery to Rebuild Trust in Government (E.O. 14058).8 This guidance will help ensure that individuals can continue to benefit from audio-only telehealth by clarifying how covered entities can provide telehealth services and improving public confidence that covered entities are protecting the privacy and security of their health information.\n",
    "\n",
    "In addition, while telehealth can significantly expand access to health care, certain populations may have difficulty accessing or be unable to access technologies used for audio-video telehealth because of various factors, including financial resources, limited English proficiency, disability, internet access, availability of sufficient broadband, and cell coverage in the geographic area.  Audio-only telehealth, especially using technologies that do not require broadband availability, can help address the needs of some of these individuals.9  To support access to such telehealth services, this guidance addresses questions that HHS has received about whether, and in what circumstances, audio-only telehealth is permissible under the HIPAA Rules.10  This guidance also addresses questions about the applicability of the HIPAA Rules to covered entities’ use of remote communication technologies to provide audio-only telehealth services.11\n",
    "\n",
    "OCR’s Telehealth Notification and FAQs\n",
    "In March 2020, in response to the COVID-19 public health emergency (PHE), OCR issued the Telehealth Notification to assist the health care industry’s response to the PHE and to quickly expand the use of remote health care services.  OCR also published a set of FAQs to support and clarify the Telehealth Notification.11\n",
    "\n",
    "The Telehealth Notification provides that OCR will exercise its enforcement discretion and will not impose penalties on covered health care providers12 for noncompliance with the requirements of the HIPAA Rules in connection with the good faith provision of telehealth using non-public facing13 audio or video remote communication technologies during the COVID-19 PHE.14  As such, under the Telehealth Notification, covered health care providers can use any available non-public facing remote communication technologies for telehealth, even where those technologies, and the manner in which they are used, may not fully comply with the HIPAA Rules.  The Telehealth Notification will remain in effect until the Secretary of HHS declares that the COVID-19 PHE no longer exists, or upon the expiration date of the declared PHE, whichever occurs first.  \n",
    "\n",
    "The following FAQs provide guidance to assist covered entities in complying with the HIPAA Rules when OCR’s Telehealth Notification is no longer in effect. \n",
    "\n",
    "1.  Does the HIPAA Privacy Rule permit covered health care providers and health plans to use remote communication technologies to provide audio-only telehealth services?\n",
    "\n",
    "Yes. HIPAA covered entities can use remote communication technologies to provide telehealth services, including audio-only services, in compliance with the HIPAA Privacy Rule.  \n",
    "\n",
    "The HIPAA Privacy Rule requires that covered entities apply reasonable safeguards to protect the privacy of protected health information (PHI) from impermissible uses or disclosures, including when providing telehealth services.15   For example, OCR expects covered health care providers to provide telehealth services in private settings to the extent feasible.  If telehealth services cannot be provided in a private setting (e.g., where a provider shares an office with a colleague or a family member), covered health care providers still must implement reasonable safeguards, such as using lowered voices and not using speakerphone, to limit incidental uses or disclosures of PHI.16\n",
    "\n",
    "In addition, if the individual is not known to the covered entity, the entity must verify the identity of the individual either orally or in writing (which may include using electronic methods).17  The HIPAA Rules do not mandate a specific way to verify identity. However, covered entities should be mindful that civil rights laws generally require communications with an individual with a disability to be as effective as communications with others, including by providing appropriate auxiliary aids and services where necessary.18   This requirement extends to all communications with an individual with a disability, including communications related to verifying an individual’s identity.  In addition, when necessary, covered entities must verify the individual’s identity by using language assistance services to provide meaningful access for individuals with limited English proficiency.19\n",
    "\n",
    "2.  Do covered health care providers and health plans have to meet the requirements of the HIPAA Security Rule in order to use remote communication technologies to provide audio-only telehealth services?\n",
    "\n",
    "Yes, in certain circumstances. The HIPAA Security Rule applies to electronic protected health information (ePHI), which is PHI transmitted by, or maintained in, electronic media.20 , 21\n",
    "\n",
    "The HIPAA Security Rule does not apply to audio-only telehealth services provided by a covered entity that is using a standard telephone line, often described as a traditional landline,22  because the information transmitted is not electronic.  Accordingly, a covered entity does not need to apply the Security Rule safeguards to telehealth services that they provide using such traditional landlines (regardless of the type of telephone technology the individual uses).\n",
    "\n",
    "However, traditional landlines are rapidly being replaced with electronic communication technologies such as Voice over Internet Protocol (VoIP)23 and mobile technologies that use electronic media, such as the Internet, intra- and extranets, cellular, and Wi-Fi.24   The HIPAA Security Rule applies when a covered entity uses such electronic communication technologies.  Covered entities using telephone systems that transmit ePHI need to apply the HIPAA Security Rule safeguards to those technologies.  Note that an individual receiving telehealth services may use any telephone system they choose and is not bound by the HIPAA Rules when doing so. In addition, a covered entity is not responsible for the privacy or security of individuals’ health information once it has been received by the individual’s phone or other device.   \n",
    "\n",
    "For example, some current electronic technologies that covered entities use for remote communications that require compliance with the Security Rule, may include:\n",
    "\n",
    "Communication applications (apps) on a smartphone or another computing device.\n",
    "VoIP technologies.\n",
    "Technologies that electronically record or transcribe a telehealth session.\n",
    "Messaging services that electronically store audio messages. \n",
    "Potential risks and vulnerabilities to the confidentiality, integrity, and availability of ePHI when using such technologies need to be identified, assessed, and addressed as part of a covered entity’s risk analysis and risk management processes, as required by the HIPAA Security Rule.25    A covered entity’s risk analysis and risk management should include considerations of whether:\n",
    "\n",
    "There is a risk the transmission could be intercepted by an unauthorized third party. \n",
    "The remote communication technology (e.g., mobile device, app) supports encrypted transmissions.\n",
    "There is a risk ePHI created or stored as a result of a telehealth session (e.g., session recordings or transcripts) could be accessed by an unauthorized third party, and whether encryption is available to secure recordings or transcripts of created or stored telehealth sessions.26    \n",
    "Authentication is required to access the device or app where telehealth session ePHI may be stored.\n",
    "The device or app automatically terminates the session or locks after a period of inactivity.\n",
    "As communication technologies (e.g., networks, devices, apps) continue to evolve at a rapid pace, a robust inventory and asset management process can help covered entities identify such technologies and the information systems that use them, to help ensure an accurate and thorough risk analysis.27  For information about implementing the HIPAA Security Rule requirements, see OCR’s Security Rule guidance webpage.28\n",
    "\n",
    "3.  Do the HIPAA Rules permit a covered health care provider or a health plan to conduct audio-only telehealth using remote communication technologies without a business associate agreement in place with the vendor? \n",
    "\n",
    "Yes, in some circumstances.  The HIPAA Rules require a covered entity to enter into a business associate agreement (BAA)29 with a telecommunication service provider30 (TSP) only when the vendor is acting as a business associate.31  As explained in previous guidance, a covered entity using a telephone to communicate with patients is not required to enter into a BAA with a TSP that has only transient access to the PHI it transmits,32 because the vendor is acting merely as a conduit for the PHI.33  If the TSP is not also creating, receiving, or maintaining PHI on behalf of the covered entity, and the TSP does not require access on a routine basis to the PHI it transmits in the call,34 no business associate relationship has been created.  Therefore, a BAA is not needed.\n",
    "\n",
    "For example, a covered health care provider may conduct an audio-only telehealth session with a patient using a smartphone without a BAA between the covered health care provider and the TSP, where the TSP does not create, receive, or maintain any PHI from the session and is only connecting the call. \n",
    "However, a covered entity must enter into a BAA with a vendor that is more than a mere conduit for PHI. \n",
    "\n",
    "For example, a covered health care provider may want to conduct audio-only telehealth sessions with patients using a smartphone app offered by a health care provider that stores PHI (e.g., recordings, transcripts) in the app developer’s cloud infrastructure for the provider’s later use. In this case, the app would not be providing mere data transmission services and would instead also be creating, receiving, and maintaining PHI.  Because it is not merely a conduit for transmission of the PHI, the provider would need to enter into a BAA with the app developer before it can use the app with patients.  \n",
    "Similarly, a covered health care provider would need a BAA with the developer of a smartphone app that the provider uses to translate oral communications to another language to provide meaningful access to individuals with limited English proficiency,35 because the app is creating and receiving PHI, and therefore the developer is a business associate of the provider.36\n",
    "4.  Do the HIPAA Rules allow covered health care providers to use remote communication technologies to provide audio-only telehealth if an individual’s health plan does not provide coverage or payment for those services?\n",
    "\n",
    "Yes.  Covered health care providers may offer audio-only telehealth services using remote communication technologies consistent with the requirements of the HIPAA Rules, regardless of whether any health plan covers or pays for those services. Health plan coverage and payment policies for health care services delivered via telehealth are separate from questions about compliance with the HIPAA Rules and are not addressed in this document.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2372 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2372"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(txt, add_special_tokens=False)\n",
    "len(tokens['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokens['input_ids']\n",
    "attention_mask = tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6786,\n",
       " 2475,\n",
       " 2000,\n",
       " 3073,\n",
       " 5746,\n",
       " 1011,\n",
       " 2069,\n",
       " 10093,\n",
       " 11106,\n",
       " 15879,\n",
       " 2705,\n",
       " 2509,\n",
       " 2578,\n",
       " 2043]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[16:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start=0\n",
      "end=512\n",
      "start=512\n",
      "end=1024\n",
      "start=1024\n",
      "end=1536\n",
      "start=1536\n",
      "end=2048\n",
      "start=2048\n",
      "end=2372\n"
     ]
    }
   ],
   "source": [
    "# define our starting position (0) and window size (number of tokens in each chunk)\n",
    "start = 0\n",
    "window_size = 512\n",
    "\n",
    "# get the total length of our tokens\n",
    "total_len = len(input_ids)\n",
    "\n",
    "# initialize condition for our while loop to run\n",
    "loop = True\n",
    "\n",
    "# loop through and print out start/end positions\n",
    "while loop:\n",
    "    # the end position is simply the start + window_size\n",
    "    end = start + window_size\n",
    "    # if the end position is greater than the total length, make this our final iteration\n",
    "    if end >= total_len:\n",
    "        loop = False\n",
    "        # and change our endpoint to the final token position\n",
    "        end = total_len\n",
    "    print(f\"{start=}\\n{end=}\")\n",
    "    # we need to move the window to the next 512 tokens\n",
    "    start = end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This logic works for shifting our window across the full length of input IDs, so now we can modify it to iterately predict sentiment for each window. There will be a few added steps for us to get this to work:\n",
    "\n",
    "1. Extract the window from `input_ids` and `attention_mask`.\n",
    "\n",
    "2. Add the start of sequence token `[CLS]`/`101` and seperator token `[SEP]`/`102`.\n",
    "\n",
    "3. Add padding (only applicable to final batch).\n",
    "\n",
    "4. Format into dictionary containing PyTorch tensors.\n",
    "\n",
    "5. Make logits predictions with the model.\n",
    "\n",
    "6. Calculate softmax and append softmax vector to a list `probs_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.0593, 0.0255, 0.9152]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.0226, 0.0528, 0.9246]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.0218, 0.0739, 0.9044]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.0222, 0.0527, 0.9250]], grad_fn=<SoftmaxBackward0>),\n",
       " tensor([[0.0260, 0.0410, 0.9330]], grad_fn=<SoftmaxBackward0>)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize probabilities list\n",
    "probs_list = []\n",
    "\n",
    "start = 0\n",
    "window_size = 510  # we take 2 off here so that we can fit in our [CLS] and [SEP] tokens\n",
    "\n",
    "loop = True\n",
    "\n",
    "while loop:\n",
    "    end = start + window_size\n",
    "    if end >= total_len:\n",
    "        loop = False\n",
    "        end = total_len\n",
    "    # (1) extract window from input_ids and attention_mask\n",
    "    input_ids_chunk = input_ids[start:end]\n",
    "    attention_mask_chunk = attention_mask[start:end]\n",
    "    # (2) add [CLS] and [SEP]\n",
    "    input_ids_chunk = [101] + input_ids_chunk + [102]\n",
    "    attention_mask_chunk = [1] + attention_mask_chunk + [1]\n",
    "    # (3) add padding upto window_size + 2 (512) tokens\n",
    "    input_ids_chunk += [0] * (window_size - len(input_ids_chunk) + 2)\n",
    "    attention_mask_chunk += [0] * (window_size - len(attention_mask_chunk) + 2)\n",
    "    # (4) format into PyTorch tensors dictionary\n",
    "    input_dict = {\n",
    "        'input_ids': torch.Tensor([input_ids_chunk]).long(),\n",
    "        'attention_mask': torch.Tensor([attention_mask_chunk]).int()\n",
    "    }\n",
    "    # (5) make logits prediction\n",
    "    outputs = model(**input_dict)\n",
    "    # (6) calculate softmax and append to list\n",
    "    probs = torch.nn.functional.softmax(outputs[0], dim=-1)\n",
    "    probs_list.append(probs)\n",
    "\n",
    "    start = end\n",
    "    \n",
    "# let's view the probabilities given\n",
    "probs_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each section has been assign varying levels of sentiment. All sections score *neutral* (index *2*). To calculate the average sentiment across the full text, we will merge these tensors using the `stack` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0593, 0.0255, 0.9152]],\n",
       "\n",
       "        [[0.0226, 0.0528, 0.9246]],\n",
       "\n",
       "        [[0.0218, 0.0739, 0.9044]],\n",
       "\n",
       "        [[0.0222, 0.0527, 0.9250]],\n",
       "\n",
       "        [[0.0260, 0.0410, 0.9330]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_probs = torch.stack(probs_list)\n",
    "stacked_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0304, 0.0492, 0.9204]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_probs.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot resize variables that require grad",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26192/2517408852.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstacked_probs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstacked_probs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacked_probs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: cannot resize variables that require grad"
     ]
    }
   ],
   "source": [
    "stacked_probs.resize_((stacked_probs.shape[0], stacked_probs.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    stacked_probs = torch.stack(probs_list)\n",
    "    stacked_probs.resize_((stacked_probs.shape[0], stacked_probs.shape[2]))\n",
    "    # get the average of the probabilities across all chunks\n",
    "    avg_probs = stacked_probs.mean(dim=0)\n",
    "    # get the argmax of the average probabilities\n",
    "    sentiment = torch.argmax(avg_probs).item()\n",
    "\n",
    "sentiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
